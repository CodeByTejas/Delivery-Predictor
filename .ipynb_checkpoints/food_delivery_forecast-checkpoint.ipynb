{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Delivery Demand Forecasting\n",
    "\n",
    "This notebook implements a machine learning-based demand forecasting system for food delivery orders using historical data, weather patterns, and other external factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "WEATHER_API_KEY = os.getenv('WEATHER_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def fetch_weather_data(city, days=5):\n",
    "    \"\"\"Fetch weather data for a specific city\"\"\"\n",
    "    base_url = \"http://api.weatherapi.com/v1/forecast.json\"\n",
    "    params = {\n",
    "        'key': WEATHER_API_KEY,\n",
    "        'q': city,\n",
    "        'days': days\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_sample_historical_data(days=180):\n",
    "    \"\"\"Generate sample historical order data\"\"\"\n",
    "    dates = pd.date_range(end=datetime.now(), periods=days)\n",
    "    \n",
    "    data = {\n",
    "        'date': dates,\n",
    "        'orders': np.random.normal(1000, 200, days),  # Random order numbers\n",
    "        'temperature': np.random.normal(25, 5, days),\n",
    "        'is_weekend': dates.weekday >= 5,\n",
    "        'is_holiday': np.random.choice([0, 1], size=days, p=[0.95, 0.05]),\n",
    "        'promotion_active': np.random.choice([0, 1], size=days, p=[0.8, 0.2])\n",
    "    }\n",
    "    \n",
    "    # Add time-based patterns\n",
    "    data['orders'] += np.where(data['is_weekend'], 200, 0)  # More orders on weekends\n",
    "    data['orders'] += np.where(data['promotion_active'], 150, 0)  # More orders during promotions\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def prepare_features(df):\n",
    "    \"\"\"Prepare features for the model\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Extract time-based features\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['month'] = df['date'].dt.month\n",
    "    \n",
    "    # Create time windows for different meal times\n",
    "    df['is_lunch_time'] = df['hour'].between(11, 14)\n",
    "    df['is_dinner_time'] = df['hour'].between(18, 21)\n",
    "    \n",
    "    # Convert boolean columns to int\n",
    "    boolean_columns = ['is_weekend', 'is_holiday', 'promotion_active', \n",
    "                      'is_lunch_time', 'is_dinner_time']\n",
    "    for col in boolean_columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_xgboost_model(X_train, y_train):\n",
    "    \"\"\"Train XGBoost model for demand forecasting\"\"\"\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_arima_model(y_train):\n",
    "    \"\"\"Train ARIMA model for time series forecasting\"\"\"\n",
    "    model = ARIMA(y_train, order=(1, 1, 1))\n",
    "    return model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"Calculate model performance metrics\"\"\"\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "    \n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    print(f\"Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "    print(f\"Root Mean Square Error: {rmse:.2f}\")\n",
    "    \n",
    "    return mae, mape, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate sample data\n",
    "df = generate_sample_historical_data()\n",
    "\n",
    "# Prepare features\n",
    "df_processed = prepare_features(df)\n",
    "\n",
    "# Split features and target\n",
    "feature_columns = ['temperature', 'is_weekend', 'is_holiday', 'promotion_active',\n",
    "                  'hour', 'day_of_week', 'month', 'is_lunch_time', 'is_dinner_time']\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed['orders']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train models\n",
    "xgb_model = train_xgboost_model(X_train, y_train)\n",
    "arima_model = train_arima_model(y_train)\n",
    "\n",
    "# Make predictions\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "arima_predictions = arima_model.forecast(len(y_test))\n",
    "\n",
    "# Evaluate models\n",
    "print(\"XGBoost Model Performance:\")\n",
    "xgb_metrics = evaluate_model(y_test, xgb_predictions)\n",
    "\n",
    "print(\"\\nARIMA Model Performance:\")\n",
    "arima_metrics = evaluate_model(y_test, arima_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_predictions(y_true, y_pred_xgb, y_pred_arima):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_true.index, y_true.values, label='Actual', color='blue')\n",
    "    plt.plot(y_true.index, y_pred_xgb, label='XGBoost', color='red')\n",
    "    plt.plot(y_true.index, y_pred_arima, label='ARIMA', color='green')\n",
    "    plt.title('Actual vs Predicted Demand')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Number of Orders')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot results\n",
    "plot_predictions(y_test, xgb_predictions, arima_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}